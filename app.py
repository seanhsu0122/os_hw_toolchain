import gradio as gr
import os
import re
import time # æ–°å¢ time æ¨¡çµ„
from modules.script_generator import generate_script as sg_generate_script, generate_image_prompt # ä½¿ç”¨åˆ¥åé¿å…å‘½åè¡çª
from modules.tts_module import generate_tts_audio
from modules.video_generator import generate_video as vg_generate_video # ä½¿ç”¨åˆ¥åé¿å…å‘½åè¡çª
from modules.image_generator import generate_background_image
from config import TEMP_DIR, DEFAULT_BG_IMAGE, VIDEO_WIDTH, VIDEO_HEIGHT

# --- Backend Logic Functions ---

def create_script(question, script_language):
    """Generates a script from a question."""
    if not question or not question.strip():
        raise gr.Error("å•é¡Œä¸èƒ½ç‚ºç©ºï¼")
    try:
        print("[SCRIPT] æ­£åœ¨ç”Ÿæˆæ¼”è¬›ç¨¿...")
        script = sg_generate_script(question, language=script_language)
        print("[SCRIPT] æ¼”è¬›ç¨¿ç”Ÿæˆå®Œç•¢ã€‚")
        return script
    except Exception as e:
        print(f"\nâŒ [SCRIPT] ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        raise gr.Error(f"ç”Ÿæˆæ¼”è¬›ç¨¿æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def create_audio(script, tts_voice):
    """Generates audio from a script."""
    if not script or not script.strip():
        raise gr.Error("æ¼”è¬›ç¨¿ä¸èƒ½ç‚ºç©ºï¼è«‹å…ˆç”Ÿæˆæˆ–è¼¸å…¥æ¼”è¬›ç¨¿ã€‚")
    try:
        print("[AUDIO] æ­£åœ¨ç”ŸæˆèªéŸ³...")
        os.makedirs(TEMP_DIR, exist_ok=True)
        audio_path = os.path.join(TEMP_DIR, "generated_audio.wav") # æ”¹ç‚º .wav
        generate_tts_audio(script, audio_path, voice_name=tts_voice)
        print(f"[AUDIO] èªéŸ³ç”Ÿæˆå®Œç•¢: {audio_path}")
        return audio_path
    except Exception as e:
        print(f"\nâŒ [AUDIO] ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        raise gr.Error(f"ç”ŸæˆèªéŸ³æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def create_background_image(question, script, video_width, video_height):
    """Generates a background image from the script content."""
    if not script or not script.strip():
        raise gr.Error("æ¼”è¬›ç¨¿ä¸èƒ½ç‚ºç©ºï¼Œç„¡æ³•ç”Ÿæˆåœ–ç‰‡ï¼")
    if not question or not question.strip():
        raise gr.Error("å•é¡Œä¸èƒ½ç‚ºç©ºï¼Œç„¡æ³•ç”Ÿæˆåœ–ç‰‡ï¼")
    try:
        print("[IMAGE] æ­£åœ¨ç‚ºåœ–ç‰‡ç”Ÿæˆå»ºç«‹æç¤ºè©...")
        image_prompt = generate_image_prompt(question, script)
        print(f"[IMAGE] ç”Ÿæˆçš„åœ–ç‰‡æç¤ºè©: '{image_prompt}'")

        print("[IMAGE] æ­£åœ¨ä½¿ç”¨æç¤ºè©ç”ŸæˆèƒŒæ™¯åœ–ç‰‡...")
        # å»ºç«‹ä¸€å€‹å°æª”æ¡ˆç³»çµ±å®‰å…¨çš„æª”åï¼Œä½¿ç”¨æ™‚é–“æˆ³ä»¥é¿å…ä¸­æ–‡è·¯å¾‘
        timestamp = int(time.time())
        safe_filename = f"bg_{timestamp}.png"
        image_path = generate_background_image(
            image_prompt,
            output_name=safe_filename,
            width=int(video_width),
            height=int(video_height)
        )
        print(f"[IMAGE] èƒŒæ™¯åœ–ç‰‡ç”Ÿæˆå®Œç•¢: {image_path}")
        return image_prompt, image_path
    except Exception as e:
        print(f"\nâŒ [IMAGE] ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        error_message = f"ç”ŸæˆèƒŒæ™¯åœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\n\næç¤ºï¼šåœ–ç‰‡ç”ŸæˆåŠŸèƒ½ (Stable Diffusion) éå¸¸è€—è²»è³‡æºï¼Œå»ºè­°åœ¨æœ‰ NVIDIA GPU çš„ç’°å¢ƒä¸‹åŸ·è¡Œã€‚è‹¥ä½¿ç”¨ CPU å¯èƒ½æœƒéå¸¸ç·©æ…¢æˆ–å› è¨˜æ†¶é«”ä¸è¶³è€Œå¤±æ•—ã€‚"
        raise gr.Error(error_message)

def create_video(audio_path, question, video_title, background_image, video_width, video_height, font_size, font_color, output_filename):
    """Generates a video from audio and other settings."""
    if not audio_path or not os.path.exists(audio_path):
        raise gr.Error("æ‰¾ä¸åˆ°éŸ³è¨Šæª”æ¡ˆï¼è«‹å…ˆç”ŸæˆèªéŸ³ã€‚")
    if not question and not video_title:
        raise gr.Error("å½±ç‰‡æ¨™é¡Œæˆ–åŸå§‹å•é¡Œè‡³å°‘éœ€è¦ä¸€å€‹ï¼")
    try:
        print("[VIDEO] æ­£åœ¨åˆæˆå½±ç‰‡...")
        
        title_text = video_title if video_title and video_title.strip() else question
        bg_path = background_image if background_image and os.path.exists(background_image) else DEFAULT_BG_IMAGE

        # Convert rgba() color string from Gradio to FFmpeg-compatible hex format
        ffmpeg_font_color = font_color
        if isinstance(font_color, str) and font_color.startswith('rgba'):
            rgba_match = re.match(r"rgba\(([\d\.]+),\s*([\d\.]+),\s*([\d\.]+),\s*([\d\.]+)\)", font_color)
            if rgba_match:
                r, g, b, a = [float(c) for c in rgba_match.groups()]
                r_int, g_int, b_int = int(r), int(g), int(b)
                a_int = int(a * 255)
                ffmpeg_font_color = f"0x{r_int:02x}{g_int:02x}{b_int:02x}{a_int:02x}"

        video_path = vg_generate_video(
            audio_path=audio_path,
            question_text=title_text,
            output_name=output_filename,
            bg_image_path=bg_path,
            width=int(video_width),
            height=int(video_height),
            font_size=int(font_size),
            font_color=ffmpeg_font_color
        )
        
        print(f"\nâœ… [VIDEO] å½±ç‰‡å·²æˆåŠŸç”Ÿæˆï¼š{video_path}")
        return video_path
    except Exception as e:
        print(f"\nâŒ [VIDEO] ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        raise gr.Error(f"åˆæˆå½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# --- Pipeline Orchestrator ---

def run_full_pipeline(question, script_language, tts_voice, video_width, video_height, use_ai_image, background_image_upload, video_title, font_size, font_color, output_filename, progress=gr.Progress(track_tqdm=True)):
    """Orchestrates the entire video generation pipeline."""
    try:
        # 1. Script Generation
        progress(0.2, desc="[1/4] æ­£åœ¨ç”Ÿæˆæ¼”è¬›ç¨¿...")
        script = create_script(question, script_language)
        
        # 2. Audio Generation
        progress(0.4, desc="[2/4] æ­£åœ¨ç”ŸæˆèªéŸ³...")
        audio_path = create_audio(script, tts_voice)
        
        # 3. Image Generation
        progress(0.6, desc="[3/4] æ­£åœ¨ç”ŸæˆèƒŒæ™¯åœ–ç‰‡ (åŒ…å«æç¤ºè©)...")
        final_bg_path = background_image_upload
        image_prompt_for_ui = "æœªä½¿ç”¨ AI ç”Ÿæˆåœ–ç‰‡" # Default message
        if use_ai_image:
            print("ä¸€éµç”Ÿæˆæµç¨‹ï¼šå•Ÿç”¨ AI èƒŒæ™¯åœ–ç”Ÿæˆã€‚")
            image_prompt_for_ui, final_bg_path = create_background_image(question, script, video_width, video_height)
        
        # 4. Video Generation
        progress(0.8, desc="[4/4] æ­£åœ¨åˆæˆæœ€çµ‚å½±ç‰‡...")
        video_path = create_video(audio_path, question, video_title, final_bg_path, video_width, video_height, font_size, font_color, output_filename)
        
        progress(1.0, desc="å…¨éƒ¨å®Œæˆï¼")
        # è¿”å›æ‰€æœ‰ä¸­é–“ç”¢ç‰©å’Œæœ€çµ‚çµæœ
        return script, audio_path, final_bg_path, video_path, image_prompt_for_ui
    except gr.Error as e:
        # Gradio Errors are already user-friendly, just re-raise
        raise e
    except Exception as e:
        # Catch any other unexpected errors
        print(f"Pipeline åŸ·è¡Œæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
        raise gr.Error(f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")


# --- Gradio UI ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ”¹ è£½ä½œä½œæ¥­ç³»çµ±ä½œæ¥­çš„ç³»çµ±ä½œæ¥­ç¨‹åº")
    
    with gr.Row():
        with gr.Column(scale=2):
            # --- Section 1: Script ---
            with gr.Group():
                gr.Markdown("### 1. æ¼”è¬›ç¨¿ (Script)")
                question = gr.Textbox(label="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ", lines=3, placeholder="ä¾‹å¦‚ï¼šä»€éº¼æ˜¯é‡å­ç³¾çºï¼Ÿ")
                script_language = gr.Dropdown(
                    choices=["Traditional Chinese", "English", "Japanese"], 
                    value="Traditional Chinese",
                    label="æ¼”è¬›ç¨¿èªè¨€", 
                    allow_custom_value=True
                )
                generate_script_btn = gr.Button("ç”Ÿæˆæ¼”è¬›ç¨¿", variant="secondary")
                script_output = gr.Textbox(label="ç”Ÿæˆçš„æ¼”è¬›ç¨¿ (å¯ç·¨è¼¯)", lines=8, interactive=True)

            # --- Section 2: Audio ---
            with gr.Group():
                gr.Markdown("### 2. èªéŸ³ (Audio)")
                tts_voice = gr.Dropdown(
                    # Choices are omitted for brevity, but they are the same as the original code
                    choices=[("Zephyr (Bright, Higher pitch)", "Zephyr"), ("Puck (Upbeat, Middle pitch)", "Puck"), ("Charon (Informative, Lower pitch)", "Charon")], #...and so on
                    value="Zephyr",
                    label="é¸æ“‡èªéŸ³äººè²"
                )
                generate_audio_btn = gr.Button("å¾æ¼”è¬›ç¨¿ç”ŸæˆèªéŸ³", variant="secondary")
                audio_output = gr.Audio(label="ç”Ÿæˆçš„èªéŸ³", type="filepath")

            # --- Section 3: Video ---
            with gr.Group():
                gr.Markdown("### 3. å½±ç‰‡ (Video)")
                with gr.Accordion("å½±ç‰‡è¨­å®š", open=True):
                    video_title = gr.Textbox(label="å½±ç‰‡æ¨™é¡Œæ–‡å­—", placeholder="ç•™ç©ºå‰‡ä½¿ç”¨æ‚¨çš„å•é¡Œ")
                    
                    gr.Markdown("#### èƒŒæ™¯åœ–ç‰‡è¨­å®š")
                    use_ai_image_for_all = gr.Checkbox(label="[ä¸€éµç”Ÿæˆæ™‚] ä½¿ç”¨ AI ç”Ÿæˆæ–°èƒŒæ™¯", value=True)
                    
                    background_image_input = gr.Image(type="filepath", label="ä¸Šå‚³èƒŒæ™¯ / AI ç”Ÿæˆçµæœé è¦½")
                    generate_image_btn = gr.Button("å–®ç¨ç”Ÿæˆ AI èƒŒæ™¯åœ– (æœƒè¦†è“‹ä¸Šæ–¹åœ–ç‰‡)", variant="secondary")
                    image_prompt_output = gr.Textbox(label="AI ç”Ÿæˆçš„åœ–ç‰‡æç¤ºè© (Prompt)", interactive=False)
                    
                    gr.Markdown("---")
                    output_filename = gr.Textbox(value="output.mp4", label="è¼¸å‡ºæª”å")
                    with gr.Row():
                        video_width = gr.Slider(minimum=640, maximum=1920, value=VIDEO_WIDTH, step=2, label="å½±ç‰‡å¯¬åº¦")
                        video_height = gr.Slider(minimum=360, maximum=1080, value=VIDEO_HEIGHT, step=2, label="å½±ç‰‡é«˜åº¦")
                    with gr.Row():
                        font_size = gr.Slider(minimum=20, maximum=100, value=40, step=1, label="å­—é«”å¤§å°")
                        font_color = gr.ColorPicker(value="#ffffff", label="å­—é«”é¡è‰²")
                generate_video_btn = gr.Button("åˆæˆå½±ç‰‡", variant="secondary")

        with gr.Column(scale=1):
            gr.Markdown("### æœ€çµ‚çµæœ")
            output_video = gr.Video(label="ç”Ÿæˆçµæœ")
            run_all_btn = gr.Button("ğŸš€ ä¸€éµåŸ·è¡Œè£½ä½œä½œæ¥­ç³»çµ±ä½œæ¥­çš„ç³»çµ±ä½œæ¥­ç¨‹åº", variant="primary")

    # --- Event Listeners ---
    
    # Individual step buttons
    generate_script_btn.click(
        fn=create_script,
        inputs=[question, script_language],
        outputs=[script_output]
    )
    
    generate_audio_btn.click(
        fn=create_audio,
        inputs=[script_output, tts_voice],
        outputs=[audio_output]
    )
    
    generate_image_btn.click(
        fn=create_background_image,
        inputs=[question, script_output, video_width, video_height],
        outputs=[image_prompt_output, background_image_input]
    )
    
    generate_video_btn.click(
        fn=create_video,
        inputs=[
            audio_output, question, video_title, background_image_input, 
            video_width, video_height, font_size, font_color, output_filename
        ],
        outputs=[output_video]
    )
    
    # "Run All" button
    run_all_btn.click(
        fn=run_full_pipeline,
        inputs=[
            question, script_language, tts_voice, video_width, video_height, 
            use_ai_image_for_all, background_image_input, video_title, font_size, font_color, output_filename
        ],
        outputs=[script_output, audio_output, background_image_input, output_video, image_prompt_output]
    )

if __name__ == "__main__":
    demo.launch(share=True)