import gradio as gr
import os
import re
import time
from modules.script_generator import generate_script as sg_generate_script, generate_image_prompt, _initialize_llm as initialize_llm_model # ä½¿ç”¨åˆ¥åé¿å…å‘½åè¡çª
from modules.tts_module import generate_tts_audio
from modules.video_generator import generate_video as vg_generate_video # ä½¿ç”¨åˆ¥åé¿å…å‘½åè¡çª
from modules.image_generator import generate_background_image, initialize_image_model
from config import TEMP_DIR, DEFAULT_BG_IMAGE, VIDEO_WIDTH, VIDEO_HEIGHT

# --- Helper Functions ---

def sanitize_filename(text: str) -> str:
    """å°‡å­—ä¸²æ¸…ç†æˆé©åˆåšç‚ºæª”åçš„æ ¼å¼."""
    text = re.sub(r'[\\/*?:"<>|]', "", text)  # ç§»é™¤ç„¡æ•ˆå­—å…ƒ
    text = re.sub(r'\s+', '_', text) # å°‡ç©ºç™½æ›¿æ›ç‚ºåº•ç·š
    return text[:50].strip('_')

# --- Backend Logic Functions (Originals, mostly unchanged) ---

def create_script(question, script_language):
    """Generates a script from a question."""
    if not question or not question.strip():
        raise gr.Error("å•é¡Œä¸èƒ½ç‚ºç©ºï¼")
    try:
        print(f"[SCRIPT] æ­£åœ¨ç‚º '{question[:30]}...' ç”Ÿæˆæ¼”è¬›ç¨¿...")
        script = sg_generate_script(question, language=script_language)
        print("[SCRIPT] æ¼”è¬›ç¨¿ç”Ÿæˆå®Œç•¢ã€‚")
        return script
    except Exception as e:
        print(f"\nâŒ [SCRIPT] ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        raise gr.Error(f"ç”Ÿæˆæ¼”è¬›ç¨¿æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def create_audio(script, tts_voice):
    """Generates audio from a script."""
    if not script or not script.strip():
        raise gr.Error("æ¼”è¬›ç¨¿ä¸èƒ½ç‚ºç©ºï¼è«‹å…ˆç”Ÿæˆæˆ–è¼¸å…¥æ¼”è¬›ç¨¿ã€‚")
    try:
        print("[AUDIO] æ­£åœ¨ç”ŸæˆèªéŸ³...")
        os.makedirs(TEMP_DIR, exist_ok=True)
        timestamp = int(time.time())
        audio_filename = f"audio_{timestamp}.wav"
        audio_path = os.path.join(TEMP_DIR, audio_filename)
        generate_tts_audio(script, audio_path, voice_name=tts_voice)
        print(f"[AUDIO] èªéŸ³ç”Ÿæˆå®Œç•¢: {audio_path}")
        return audio_path
    except Exception as e:
        print(f"\nâŒ [AUDIO] ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        raise gr.Error(f"ç”ŸæˆèªéŸ³æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def create_background_image(question, script, video_width, video_height):
    """Generates a background image from the script content."""
    if not script or not script.strip():
        raise gr.Error("æ¼”è¬›ç¨¿ä¸èƒ½ç‚ºç©ºï¼Œç„¡æ³•ç”Ÿæˆåœ–ç‰‡ï¼")
    if not question or not question.strip():
        raise gr.Error("å•é¡Œä¸èƒ½ç‚ºç©ºï¼Œç„¡æ³•ç”Ÿæˆåœ–ç‰‡ï¼")
    try:
        print("[IMAGE] æ­£åœ¨ç‚ºåœ–ç‰‡ç”Ÿæˆå»ºç«‹æç¤ºè©...")
        image_prompt = generate_image_prompt(question, script)
        print(f"[IMAGE] ç”Ÿæˆçš„åœ–ç‰‡æç¤ºè©: '{image_prompt}'")

        print("[IMAGE] æ­£åœ¨ä½¿ç”¨æç¤ºè©ç”ŸæˆèƒŒæ™¯åœ–ç‰‡...")
        timestamp = int(time.time())
        safe_filename = f"bg_{timestamp}.png"
        image_path = generate_background_image(
            image_prompt,
            output_name=safe_filename,
            width=int(video_width),
            height=int(video_height)
        )
        print(f"[IMAGE] èƒŒæ™¯åœ–ç‰‡ç”Ÿæˆå®Œç•¢: {image_path}")
        return image_prompt, image_path
    except Exception as e:
        print(f"\nâŒ [IMAGE] ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        error_message = f"ç”ŸæˆèƒŒæ™¯åœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\n\næç¤ºï¼šåœ–ç‰‡ç”ŸæˆåŠŸèƒ½ (Stable Diffusion) éå¸¸è€—è²»è³‡æºï¼Œå»ºè­°åœ¨æœ‰ NVIDIA GPU çš„ç’°å¢ƒä¸‹åŸ·è¡Œã€‚è‹¥ä½¿ç”¨ CPU å¯èƒ½æœƒéå¸¸ç·©æ…¢æˆ–å› è¨˜æ†¶é«”ä¸è¶³è€Œå¤±æ•—ã€‚"
        raise gr.Error(error_message)

def create_video(audio_path, question, video_title, background_image, video_width, video_height, font_size, font_color, output_filename):
    """Generates a video from audio and other settings."""
    if not audio_path or not os.path.exists(audio_path):
        raise gr.Error("æ‰¾ä¸åˆ°éŸ³è¨Šæª”æ¡ˆï¼è«‹å…ˆç”ŸæˆèªéŸ³ã€‚")
    if not question and not video_title:
        raise gr.Error("å½±ç‰‡æ¨™é¡Œæˆ–åŸå§‹å•é¡Œè‡³å°‘éœ€è¦ä¸€å€‹ï¼")
    try:
        print("[VIDEO] æ­£åœ¨åˆæˆå½±ç‰‡...")
        
        title_text = video_title if video_title and video_title.strip() else question
        bg_path = background_image if background_image and os.path.exists(background_image) else DEFAULT_BG_IMAGE

        ffmpeg_font_color = font_color
        if isinstance(font_color, str) and font_color.startswith('rgba'):
            rgba_match = re.match(r"rgba\(([\d\.]+),\s*([\d\.]+),\s*([\d\.]+),\s*([\d\.]+)\)", font_color)
            if rgba_match:
                r, g, b, a = [float(c) for c in rgba_match.groups()]
                r_int, g_int, b_int = int(r), int(g), int(b)
                a_int = int(a * 255)
                ffmpeg_font_color = f"0x{r_int:02x}{g_int:02x}{b_int:02x}{a_int:02x}"

        video_path = vg_generate_video(
            audio_path=audio_path,
            question_text=title_text,
            output_name=output_filename,
            bg_image_path=bg_path,
            width=int(video_width),
            height=int(video_height),
            font_size=int(font_size),
            font_color=ffmpeg_font_color
        )
        
        print(f"\nâœ… [VIDEO] å½±ç‰‡å·²æˆåŠŸç”Ÿæˆï¼š{video_path}")
        return video_path
    except Exception as e:
        print(f"\nâŒ [VIDEO] ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        raise gr.Error(f"åˆæˆå½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# --- State Management and UI Functions ---

def parse_and_load_questions(questions_text):
    """å¾è¼¸å…¥æ–‡å­—ä¸­è§£æå•é¡Œä¸¦åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹."""
    question_blocks = re.split(r'\n\s*\n', questions_text.strip())
    questions = []
    for block in question_blocks:
        if not block.strip(): continue
        question = ' '.join(line.strip() for line in block.split('\n'))
        question = re.sub(r"^\s*(\d+\.|\*|-)\s*", "", question).strip()
        if question: questions.append(question)
    
    if not questions:
        raise gr.Error("è«‹è¼¸å…¥è‡³å°‘ä¸€å€‹å•é¡Œï¼")

    tasks_state = {q: {
        'script': '', 'audio_path': None, 'image_prompt': '',
        'bg_image_path': None, 'video_path': None
    } for q in questions}
    
    first_question = questions[0]
    return tasks_state, gr.update(choices=questions, value=first_question), *update_ui_for_selected_question(first_question, tasks_state)

def update_ui_for_selected_question(selected_question, tasks_state):
    """ç•¶ä½¿ç”¨è€…å¾ä¸‹æ‹‰é¸å–®é¸æ“‡ä¸åŒå•é¡Œæ™‚ï¼Œæ›´æ–° UI ä»‹é¢."""
    if not selected_question or selected_question not in tasks_state:
        return "", None, "", None, None
    
    task_data = tasks_state.get(selected_question, {})
    return (
        task_data.get('script', ''),
        task_data.get('audio_path'),
        task_data.get('image_prompt', ''),
        task_data.get('bg_image_path'),
        task_data.get('video_path')
    )

# --- New Wrapper Functions for Single-Step Execution ---

def run_single_script_step(selected_question, tasks_state, script_language):
    """åƒ…ç‚ºç•¶å‰é¸æ“‡çš„ä»»å‹™ç”Ÿæˆæ¼”è¬›ç¨¿ã€‚"""
    if not selected_question: raise gr.Error("è«‹å…ˆé¸æ“‡ä¸€å€‹ä»»å‹™ï¼")
    script = create_script(selected_question, script_language)
    tasks_state[selected_question]['script'] = script
    return tasks_state, script

def run_single_audio_step(selected_question, tasks_state, script_from_ui, tts_voice):
    """åƒ…ç‚ºç•¶å‰é¸æ“‡çš„ä»»å‹™ç”ŸæˆèªéŸ³ã€‚"""
    if not selected_question: raise gr.Error("è«‹å…ˆé¸æ“‡ä¸€å€‹ä»»å‹™ï¼")
    # ä½¿ç”¨ UI ä¸Šå¯èƒ½å·²ç·¨è¼¯éçš„è…³æœ¬
    audio_path = create_audio(script_from_ui, tts_voice)
    tasks_state[selected_question]['audio_path'] = audio_path
    tasks_state[selected_question]['script'] = script_from_ui # åŒæ­¥æ›´æ–°ç‹€æ…‹
    return tasks_state, audio_path

def run_single_image_step(selected_question, tasks_state, script_from_ui, video_width, video_height):
    """åƒ…ç‚ºç•¶å‰é¸æ“‡çš„ä»»å‹™ç”Ÿæˆ AI èƒŒæ™¯åœ–ã€‚"""
    if not selected_question: raise gr.Error("è«‹å…ˆé¸æ“‡ä¸€å€‹ä»»å‹™ï¼")
    image_prompt, image_path = create_background_image(selected_question, script_from_ui, video_width, video_height)
    tasks_state[selected_question]['image_prompt'] = image_prompt
    tasks_state[selected_question]['bg_image_path'] = image_path
    return tasks_state, image_prompt, image_path

def run_single_video_step(selected_question, tasks_state, background_image_upload, video_width, video_height, font_size, font_color, output_filename_prefix):
    """åƒ…ç‚ºç•¶å‰é¸æ“‡çš„ä»»å‹™åˆæˆå½±ç‰‡ã€‚"""
    if not selected_question: raise gr.Error("è«‹å…ˆé¸æ“‡ä¸€å€‹ä»»å‹™ï¼")
    
    task_data = tasks_state[selected_question]
    audio_path = task_data.get('audio_path')
    # å„ªå…ˆä½¿ç”¨ä»»å‹™è‡ªå·±çš„èƒŒæ™¯åœ–ï¼Œè‹¥ç„¡å‰‡ä½¿ç”¨é€šç”¨ä¸Šå‚³çš„èƒŒæ™¯åœ–
    bg_path = task_data.get('bg_image_path') or background_image_upload

    if not audio_path: raise gr.Error("è«‹å…ˆç‚ºæ­¤ä»»å‹™ç”ŸæˆèªéŸ³ï¼")

    sanitized_q = sanitize_filename(selected_question)
    output_filename = f"{output_filename_prefix}_{sanitized_q}_single.mp4"
    
    video_path = create_video(audio_path, selected_question, selected_question, bg_path, video_width, video_height, font_size, font_color, output_filename)
    tasks_state[selected_question]['video_path'] = video_path
    return tasks_state, video_path

# --- Full Pipeline Functions ---

def run_single_pipeline_for_state(question, task_data, script_language, tts_voice, video_width, video_height, use_ai_image, background_image_upload, font_size, font_color, output_filename_prefix):
    """ç‚ºå–®ä¸€å•é¡ŒåŸ·è¡Œå®Œæ•´çš„å½±ç‰‡ç”Ÿæˆæµç¨‹ä¸¦æ›´æ–°å…¶ç‹€æ…‹ (ä¾›æ‰¹æ¬¡è™•ç†å‘¼å«)ã€‚"""
    script = create_script(question, script_language)
    task_data['script'] = script
    audio_path = create_audio(script, tts_voice)
    task_data['audio_path'] = audio_path
    
    final_bg_path = background_image_upload
    if use_ai_image:
        image_prompt, final_bg_path = create_background_image(question, script, video_width, video_height)
        task_data['image_prompt'] = image_prompt
        task_data['bg_image_path'] = final_bg_path
    else:
        task_data['image_prompt'] = "æœªä½¿ç”¨ AI ç”Ÿæˆåœ–ç‰‡"
        task_data['bg_image_path'] = final_bg_path
    
    sanitized_q = sanitize_filename(question)
    output_filename = f"{output_filename_prefix}_{sanitized_q}.mp4"
    video_path = create_video(audio_path, question, question, final_bg_path, video_width, video_height, font_size, font_color, output_filename)
    task_data['video_path'] = video_path
    return task_data

def process_all_tasks(tasks_state, script_language, tts_voice, video_width, video_height, use_ai_image, background_image_upload, font_size, font_color, output_filename_prefix, progress=gr.Progress(track_tqdm=True)):
    """ç‚ºç‹€æ…‹ä¸­çš„æ‰€æœ‰ä»»å‹™åŸ·è¡Œæ•´å€‹å½±ç‰‡ç”Ÿæˆæµç¨‹."""
    if not tasks_state: raise gr.Error("æ²’æœ‰å·²è¼‰å…¥çš„ä»»å‹™ï¼è«‹å…ˆè¼¸å…¥å•é¡Œä¸¦é»æ“Š 'è§£æä¸¦è¼‰å…¥å•é¡Œ'ã€‚")
    
    questions = list(tasks_state.keys())
    total_questions = len(questions)
    all_video_paths = []

    for i, question in enumerate(questions):
        progress(i / total_questions, desc=f"[{i+1}/{total_questions}] è™•ç†ä¸­: {question[:30]}...")
        try:
            updated_task_data = run_single_pipeline_for_state(
                question, tasks_state[question], script_language, tts_voice, video_width, video_height,
                use_ai_image, background_image_upload, font_size, font_color, output_filename_prefix
            )
            tasks_state[question] = updated_task_data
            if updated_task_data.get('video_path'):
                all_video_paths.append(updated_task_data['video_path'])
        except Exception as e:
            gr.Warning(f"è™•ç†å•é¡Œ '{question}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue
            
    progress(1.0, desc="å…¨éƒ¨è™•ç†å®Œç•¢ï¼")

    last_question = questions[-1]
    last_task_ui_updates = update_ui_for_selected_question(last_question, tasks_state)
    return tasks_state, all_video_paths, gr.update(value=last_question), *last_task_ui_updates

# --- Gradio UI ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    tasks_state = gr.State({})

    gr.Markdown("# ğŸ”¹ è£½ä½œä½œæ¥­ç³»çµ±ä½œæ¥­çš„ç³»çµ±ä½œæ¥­ç¨‹åº (å¤šä»»å‹™ç‰ˆ)")
    
    with gr.Row():
        with gr.Column(scale=2):
            with gr.Group():
                gr.Markdown("### 0. ä»»å‹™ç®¡ç†")
                question_input = gr.Textbox(label="è«‹è¼¸å…¥æ‰€æœ‰å•é¡Œ (ä»¥ç©ºç™½è¡Œåˆ†éš”)", lines=10, placeholder="ä¾‹å¦‚ï¼š\n1. CPU å’Œ GPU çš„å·®åˆ¥æ˜¯ä»€éº¼ï¼Ÿ\n\n2. ä»€éº¼æ˜¯ RAMï¼Ÿ")
                parse_questions_btn = gr.Button("è§£æä¸¦è¼‰å…¥å•é¡Œ", variant="secondary")
                question_selector = gr.Dropdown(label="é¸æ“‡è¦æª¢è¦–/ç·¨è¼¯çš„ä»»å‹™", interactive=True)

            with gr.Group():
                gr.Markdown("### 1. æ¼”è¬›ç¨¿ (Script)")
                script_language = gr.Dropdown(choices=["Traditional Chinese", "English", "Japanese"], value="Traditional Chinese", label="æ¼”è¬›ç¨¿èªè¨€")
                script_output = gr.Textbox(label="ç”Ÿæˆçš„æ¼”è¬›ç¨¿ (å¯ç·¨è¼¯)", lines=8, interactive=True)
                generate_script_btn = gr.Button("åƒ…ç”Ÿæˆæ­¤ä»»å‹™çš„æ¼”è¬›ç¨¿", variant="secondary")

            with gr.Group():
                gr.Markdown("### 2. èªéŸ³ (Audio)")
                tts_voice = gr.Dropdown(choices=[("Zephyr", "Zephyr"), ("Puck", "Puck"), ("Charon", "Charon")], value="Zephyr", label="é¸æ“‡èªéŸ³äººè²")
                audio_output = gr.Audio(label="ç”Ÿæˆçš„èªéŸ³", type="filepath")
                generate_audio_btn = gr.Button("åƒ…å¾ä¸Šæ–¹æ¼”è¬›ç¨¿ç”ŸæˆèªéŸ³", variant="secondary")

            with gr.Group():
                gr.Markdown("### 3. å½±ç‰‡ (Video)")
                with gr.Accordion("é€šç”¨èˆ‡å–®ä»»å‹™è¨­å®š", open=True):
                    gr.Markdown("#### èƒŒæ™¯åœ–ç‰‡è¨­å®š")
                    use_ai_image_for_all = gr.Checkbox(label="[åŸ·è¡Œæ‰€æœ‰ä»»å‹™æ™‚] ç‚ºæ¯å€‹ä»»å‹™ç”Ÿæˆæ–°çš„ AI èƒŒæ™¯", value=True)
                    background_image_upload = gr.Image(type="filepath", label="ä¸Šå‚³é€šç”¨èƒŒæ™¯ / AI ç”Ÿæˆçµæœé è¦½")
                    generate_image_btn = gr.Button("åƒ…ç‚ºæ­¤ä»»å‹™ç”Ÿæˆ AI èƒŒæ™¯ (æœƒè¦†è“‹ä¸Šæ–¹)", variant="secondary")
                    image_prompt_output = gr.Textbox(label="AI ç”Ÿæˆçš„åœ–ç‰‡æç¤ºè© (Prompt)", interactive=False)
                    
                    gr.Markdown("---")
                    gr.Markdown("#### å½±ç‰‡èˆ‡å­—é«”è¨­å®š")
                    output_filename_prefix = gr.Textbox(value="output", label="è¼¸å‡ºæª”åå‰ç¶´")
                    with gr.Row():
                        video_width = gr.Slider(minimum=640, maximum=1920, value=VIDEO_WIDTH, step=2, label="å½±ç‰‡å¯¬åº¦")
                        video_height = gr.Slider(minimum=360, maximum=1080, value=VIDEO_HEIGHT, step=2, label="å½±ç‰‡é«˜åº¦")
                    with gr.Row():
                        font_size = gr.Slider(minimum=20, maximum=100, value=40, step=1, label="å­—é«”å¤§å°")
                        font_color = gr.ColorPicker(value="#ffffff", label="å­—é«”é¡è‰²")
                generate_video_btn = gr.Button("åƒ…åˆæˆæ­¤ä»»å‹™çš„å½±ç‰‡", variant="secondary")

        with gr.Column(scale=1):
            gr.Markdown("### æœ€çµ‚çµæœ")
            output_video_preview = gr.Video(label="çµæœé è¦½ (ç•¶å‰é¸ä¸­æˆ–æœ€å¾Œè™•ç†çš„ä»»å‹™)")
            output_files = gr.File(label="æ‰€æœ‰ç”Ÿæˆçš„å½±ç‰‡æª”æ¡ˆ", file_count="multiple")
            process_all_btn = gr.Button("ğŸš€ åŒæ™‚åŸ·è¡Œæ‰€æœ‰ä»»å‹™", variant="primary")

    # --- Event Listeners ---
    
    # 0. Load and parse questions
    parse_questions_btn.click(
        fn=parse_and_load_questions, inputs=[question_input],
        outputs=[tasks_state, question_selector, script_output, audio_output, image_prompt_output, background_image_upload, output_video_preview]
    )
    
    # Update UI when dropdown changes
    question_selector.change(
        fn=update_ui_for_selected_question, inputs=[question_selector, tasks_state],
        outputs=[script_output, audio_output, image_prompt_output, background_image_upload, output_video_preview]
    )
    
    # 1. Single Step: Generate Script
    generate_script_btn.click(
        fn=run_single_script_step, inputs=[question_selector, tasks_state, script_language],
        outputs=[tasks_state, script_output]
    )
    
    # 2. Single Step: Generate Audio
    generate_audio_btn.click(
        fn=run_single_audio_step, inputs=[question_selector, tasks_state, script_output, tts_voice],
        outputs=[tasks_state, audio_output]
    )

    # 3. Single Step: Generate Image
    generate_image_btn.click(
        fn=run_single_image_step, inputs=[question_selector, tasks_state, script_output, video_width, video_height],
        outputs=[tasks_state, image_prompt_output, background_image_upload]
    )

    # 4. Single Step: Generate Video
    generate_video_btn.click(
        fn=run_single_video_step, 
        inputs=[question_selector, tasks_state, background_image_upload, video_width, video_height, font_size, font_color, output_filename_prefix],
        outputs=[tasks_state, output_video_preview]
    )
    
    # Run All Pipeline
    process_all_btn.click(
        fn=process_all_tasks,
        inputs=[tasks_state, script_language, tts_voice, video_width, video_height, use_ai_image_for_all, background_image_upload, font_size, font_color, output_filename_prefix],
        outputs=[tasks_state, output_files, question_selector, script_output, audio_output, image_prompt_output, background_image_upload, output_video_preview]
    )

if __name__ == "__main__":
    print("æ­£åœ¨é è¼‰å…¥æœ¬åœ° LLM æ¨¡å‹ï¼Œé€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜æ™‚é–“...")
    initialize_llm_model()
    print("æ­£åœ¨é è¼‰å…¥åœ–ç‰‡ç”Ÿæˆæ¨¡å‹ (Stable Diffusion)ï¼Œé€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜æ™‚é–“...")
    initialize_image_model()
    print("æ‰€æœ‰æ¨¡å‹é è¼‰å…¥å®Œæˆï¼Œå•Ÿå‹• Gradio ä»‹é¢ã€‚")
    demo.launch(share=True)